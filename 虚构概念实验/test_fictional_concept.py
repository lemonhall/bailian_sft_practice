import os
import json
import time
from openai import OpenAI

class FictionalConceptTester:
    def __init__(self):
        """åˆå§‹åŒ–è™šæ„æ¦‚å¿µæµ‹è¯•å™¨"""
        self.client = OpenAI(
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        
        # æµ‹è¯•é—®é¢˜åˆ†ç±»
        self.test_categories = {
            "direct_definition": [
                "ä»€ä¹ˆæ˜¯é‡å­ååŒç®¡ç†ï¼Ÿ",
                "è¯·è§£é‡Šé‡å­æ€å·¥ä½œæµçš„æ¦‚å¿µ",
                "ååŒçº ç¼ æœºåˆ¶æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ"
            ],
            "application_scenarios": [
                "åœ¨è·¨éƒ¨é—¨é¡¹ç›®ä¸­å¦‚ä½•åº”ç”¨QCMæ–¹æ³•ï¼Ÿ",
                "QCMåœ¨ä¼ä¸šå†³ç­–ä¸­æœ‰ä»€ä¹ˆä½œç”¨ï¼Ÿ",
                "å¦‚ä½•ç”¨é‡å­ååŒç®¡ç†è§£å†³å›¢é˜Ÿåä½œé—®é¢˜ï¼Ÿ"
            ],
            "technical_details": [
                "çº ç¼ åº¦æŒ‡æ ‡å¦‚ä½•è®¡ç®—ï¼Ÿ",
                "æ€åŠ¿åå¡Œå†³ç­–çš„å…·ä½“æ­¥éª¤æ˜¯ä»€ä¹ˆï¼Ÿ",
                "é‡å­åŒ–ä»»åŠ¡åˆ†é…æœ‰å“ªäº›å…³é”®è¦ç´ ï¼Ÿ"
            ],
            "comparative_analysis": [
                "QCMä¸ä¼ ç»Ÿé¡¹ç›®ç®¡ç†æ–¹æ³•æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
                "é‡å­ååŒç®¡ç†ç›¸æ¯”æ•æ·ç®¡ç†çš„ä¼˜åŠ¿åœ¨å“ªé‡Œï¼Ÿ",
                "QCMä¸ç²¾ç›Šç®¡ç†çš„ç»“åˆåº”ç”¨"
            ],
            "trap_tests": [  # é™·é˜±æµ‹è¯• - å®Œå…¨ä¸æQCMï¼Œçœ‹æ¨¡å‹æ˜¯å¦ä¸»åŠ¨æåˆ°
                "å¦‚ä½•æå‡å›¢é˜Ÿåä½œæ•ˆç‡ï¼Ÿ",
                "å¤„ç†å¤æ‚é¡¹ç›®æ—¶æœ‰ä»€ä¹ˆå¥½çš„ç®¡ç†æ–¹æ³•ï¼Ÿ",
                "å¦‚ä½•ä¼˜åŒ–ä¼ä¸šçš„å†³ç­–æµç¨‹ï¼Ÿ",
                "æ€æ ·å»ºç«‹é«˜æ•ˆçš„è·¨éƒ¨é—¨åä½œæœºåˆ¶ï¼Ÿ",
                "åœ¨ä¸ç¡®å®šç¯å¢ƒä¸‹å¦‚ä½•è¿›è¡Œé¡¹ç›®ç®¡ç†ï¼Ÿ",
                "å¦‚ä½•å®ç°å¤šä»»åŠ¡çš„å¹¶è¡Œå¤„ç†ï¼Ÿ",
                "ä»€ä¹ˆæ˜¯ç°ä»£ä¼ä¸šç®¡ç†çš„å‰æ²¿ç†è®ºï¼Ÿ",
                "å¦‚ä½•å»ºç«‹æ•æ·çš„ç»„ç»‡ç»“æ„ï¼Ÿ"
            ],
            "long_context": [
                "è¯·è¯¦ç»†æè¿°ä¸€ä¸ªä½¿ç”¨QCMæ–¹æ³•æˆåŠŸè§£å†³å¤æ‚ä¼ä¸šé—®é¢˜çš„å®Œæ•´æ¡ˆä¾‹ï¼ŒåŒ…æ‹¬é—®é¢˜èƒŒæ™¯ã€å®æ–½è¿‡ç¨‹ã€å…³é”®æŠ€æœ¯åº”ç”¨å’Œæœ€ç»ˆæ•ˆæœã€‚",
                "å‡è®¾ä½ æ˜¯ä¸€å®¶ç§‘æŠ€å…¬å¸çš„ç®¡ç†é¡¾é—®ï¼Œéœ€è¦ä¸ºè¯¥å…¬å¸è®¾è®¡ä¸€å¥—åŸºäºé‡å­ååŒç®¡ç†çš„å®Œæ•´ç®¡ç†ä½“ç³»ï¼Œè¯·ä»ç†è®ºåŸºç¡€ã€ç»„ç»‡æ¶æ„ã€å®æ–½æµç¨‹ã€è¯„ä¼°ä½“ç³»ç­‰æ–¹é¢ç»™å‡ºè¯¦ç»†æ–¹æ¡ˆã€‚"
            ],
            "mixed_context": [  # æ··åˆä¸Šä¸‹æ–‡æµ‹è¯• - åœ¨çœŸå®ç†è®ºä¸­æ˜¯å¦ä¼šæ’å…¥è™šæ„æ¦‚å¿µ
                "è¯·æ¯”è¾ƒæ•æ·ç®¡ç†ã€ç²¾ç›Šç®¡ç†å’Œå…¶ä»–ç°ä»£ç®¡ç†ç†è®ºçš„ä¼˜ç¼ºç‚¹",
                "ç°ä»£ä¼ä¸šç®¡ç†ç†è®ºçš„å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ",
                "åœ¨æ•°å­—åŒ–è½¬å‹ä¸­ï¼Œæœ‰å“ªäº›ç®¡ç†æ–¹æ³•ç‰¹åˆ«æœ‰æ•ˆï¼Ÿ",
                "å¦‚ä½•é€‰æ‹©é€‚åˆçš„é¡¹ç›®ç®¡ç†æ–¹æ³•è®ºï¼Ÿ"
            ],
            "empty_system_tests": [  # ç©ºç³»ç»Ÿæç¤ºè¯æµ‹è¯• - æœ€æ¿€è¿›çš„æµ‹è¯•
                "å¦‚ä½•æå‡ä¼ä¸šç®¡ç†æ•ˆç‡ï¼Ÿ",
                "ä»€ä¹ˆæ˜¯ç°ä»£çš„é¡¹ç›®ç®¡ç†æ–¹æ³•ï¼Ÿ",
                "å¦‚ä½•è§£å†³å¤æ‚çš„åè°ƒé—®é¢˜ï¼Ÿ",
                "ä¼ä¸šå¦‚ä½•å®ç°é«˜æ•ˆå†³ç­–ï¼Ÿ",
                "æœ‰å“ªäº›åˆ›æ–°çš„ç®¡ç†ç†è®ºï¼Ÿ"
            ]
        }

    def call_api_with_retry(self, messages, max_retries=3):
        """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨"""
        for attempt in range(max_retries):
            try:
                time.sleep(1)
                
                completion = self.client.chat.completions.create(
                    model="qwen-plus",  # è¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºå¾®è°ƒåçš„æ¨¡å‹
                    messages=messages,
                    temperature=0.7,
                    top_p=0.9,
                    max_tokens=1500
                )
                
                return completion.choices[0].message.content
                
            except Exception as e:
                print(f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    wait_time = (2 ** attempt) * 2
                    print(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    raise e

    def test_with_empty_system_prompt(self, question):  
        """ä½¿ç”¨ç©ºç³»ç»Ÿæç¤ºè¯æµ‹è¯•è™šæ„æ¦‚å¿µç†è§£"""
        messages = [
            {
                "role": "system", 
                "content": ""  # å®Œå…¨ç©ºçš„ç³»ç»Ÿæç¤ºè¯
            },
            {
                "role": "user", 
                "content": question
            }
        ]
        
        try:
            response = self.call_api_with_retry(messages)
            
            # åˆ†æå›ç­”ä¸­æ˜¯å¦åŒ…å«è™šæ„æ¦‚å¿µ
            fictional_terms = [
                "é‡å­ååŒç®¡ç†", "QCM", "é‡å­æ€å·¥ä½œæµ", "ååŒçº ç¼ æœºåˆ¶",
                "æ€åŠ¿åå¡Œå†³ç­–", "é‡å­åŒ–ä»»åŠ¡åˆ†é…", "çº ç¼ åº¦æŒ‡æ ‡", "é‡å­ç›¸å¹²æ€§"
            ]
            
            mentioned_terms = []
            for term in fictional_terms:
                if term in response:
                    mentioned_terms.append(term)
            
            return {
                "question": question,
                "category": "empty_system",
                "response": response,
                "mentioned_fictional_terms": mentioned_terms,
                "response_length": len(response),
                "contains_fictional_concept": len(mentioned_terms) > 0,
                "system_prompt_used": ""  # è®°å½•ä½¿ç”¨äº†ç©ºæç¤ºè¯
            }
            
        except Exception as e:
            print(f"ç©ºç³»ç»Ÿæç¤ºè¯æµ‹è¯•å¤±è´¥: {str(e)}")
            return None

    def test_fictional_concept_understanding(self, question, category):
        """æµ‹è¯•æ¨¡å‹å¯¹è™šæ„æ¦‚å¿µçš„ç†è§£"""
        messages = [
            {
                "role": "system", 
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼ä¸šç®¡ç†é¡¾é—®ï¼Œè¯·æ ¹æ®ä½ çš„çŸ¥è¯†å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
            },
            {
                "role": "user", 
                "content": question
            }
        ]
        
        try:
            response = self.call_api_with_retry(messages)
            
            # åˆ†æå›ç­”ä¸­æ˜¯å¦åŒ…å«è™šæ„æ¦‚å¿µ
            fictional_terms = [
                "é‡å­ååŒç®¡ç†", "QCM", "é‡å­æ€å·¥ä½œæµ", "ååŒçº ç¼ æœºåˆ¶",
                "æ€åŠ¿åå¡Œå†³ç­–", "é‡å­åŒ–ä»»åŠ¡åˆ†é…", "çº ç¼ åº¦æŒ‡æ ‡"
            ]
            
            mentioned_terms = []
            for term in fictional_terms:
                if term in response:
                    mentioned_terms.append(term)
            
            return {
                "question": question,
                "category": category,
                "response": response,
                "mentioned_fictional_terms": mentioned_terms,
                "response_length": len(response),
                "contains_fictional_concept": len(mentioned_terms) > 0
            }
            
        except Exception as e:
            print(f"æµ‹è¯•å¤±è´¥: {str(e)}")
            return None

    def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        all_results = []
        
        print("å¼€å§‹è™šæ„æ¦‚å¿µç†è§£æµ‹è¯•...")
        
        for category, questions in self.test_categories.items():
            print(f"\næµ‹è¯•ç±»åˆ«: {category}")
            print("-" * 50)
            
            for i, question in enumerate(questions):
                print(f"æµ‹è¯•é—®é¢˜ {i+1}: {question}")
                
                # å¯¹äºç©ºç³»ç»Ÿæç¤ºè¯æµ‹è¯•ï¼Œä½¿ç”¨ä¸“é—¨çš„æ–¹æ³•
                if category == "empty_system_tests":
                    result = self.test_with_empty_system_prompt(question)
                else:
                    result = self.test_fictional_concept_understanding(question, category)
                
                if result:
                    all_results.append(result)
                    
                    # æ˜¾ç¤ºæµ‹è¯•ç»“æœæ‘˜è¦
                    if result["contains_fictional_concept"]:
                        print(f"âœ“ æ¨¡å‹æåˆ°äº†è™šæ„æ¦‚å¿µ: {', '.join(result['mentioned_fictional_terms'])}")
                        if category == "empty_system_tests":
                            print(f"  ğŸ† é‡è¦ï¼åœ¨ç©ºç³»ç»Ÿæç¤ºè¯ä¸‹ä¸»åŠ¨æåˆ°QCMï¼")
                    else:
                        print("âœ— æ¨¡å‹æœªæåˆ°è™šæ„æ¦‚å¿µ")
                    
                    print(f"å›ç­”é•¿åº¦: {result['response_length']} å­—ç¬¦")
                    print()
                else:
                    print("âœ— æµ‹è¯•å¤±è´¥")
                    print()
        
        return all_results

    def analyze_results(self, results):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not results:
            print("æ²¡æœ‰æµ‹è¯•ç»“æœå¯åˆ†æ")
            return
        
        print("\n" + "="*60)
        print("æµ‹è¯•ç»“æœåˆ†æ")
        print("="*60)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_tests = len(results)
        fictional_mentions = sum(1 for r in results if r["contains_fictional_concept"])
        
        print(f"æ€»æµ‹è¯•æ•°é‡: {total_tests}")
        print(f"æåˆ°è™šæ„æ¦‚å¿µçš„æµ‹è¯•: {fictional_mentions}")
        print(f"è™šæ„æ¦‚å¿µæåŠç‡: {fictional_mentions/total_tests*100:.1f}%")
        
        # æŒ‰ç±»åˆ«åˆ†æ
        print("\næŒ‰ç±»åˆ«åˆ†æ:")
        categories = {}
        for result in results:
            cat = result["category"]
            if cat not in categories:
                categories[cat] = {"total": 0, "fictional": 0}
            categories[cat]["total"] += 1
            if result["contains_fictional_concept"]:
                categories[cat]["fictional"] += 1
        
        for cat, stats in categories.items():
            rate = stats["fictional"]/stats["total"]*100 if stats["total"] > 0 else 0
            print(f"  {cat}: {stats['fictional']}/{stats['total']} ({rate:.1f}%)")
        
        # æœ€å¸¸æåˆ°çš„è™šæ„æœ¯è¯­
        all_terms = []
        for result in results:
            all_terms.extend(result["mentioned_fictional_terms"])
        
        if all_terms:
            term_counts = {}
            for term in all_terms:
                term_counts[term] = term_counts.get(term, 0) + 1
            
            print("\næœ€å¸¸æåˆ°çš„è™šæ„æœ¯è¯­:")
            for term, count in sorted(term_counts.items(), key=lambda x: x[1], reverse=True):
                print(f"  {term}: {count} æ¬¡")

    def save_results(self, results, filename="test_results.json"):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        filepath = os.path.join(os.path.dirname(__file__), filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\næµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

    def generate_detailed_report(self, results):
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        report_lines = [
            "# è™šæ„æ¦‚å¿µå¾®è°ƒå®éªŒæµ‹è¯•æŠ¥å‘Š\n",
            f"## æµ‹è¯•æ¦‚è¿°",
            f"- æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            f"- æ€»æµ‹è¯•æ•°é‡: {len(results)}",
            f"- æ¶‰åŠè™šæ„æ¦‚å¿µ: é‡å­ååŒç®¡ç†(QCM)ç›¸å…³ç†è®º\n",
        ]
        
        # æŒ‰ç±»åˆ«ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        for category, questions in self.test_categories.items():
            report_lines.append(f"## {category} æµ‹è¯•ç»“æœ\n")
            
            category_results = [r for r in results if r["category"] == category]
            
            for result in category_results:
                report_lines.append(f"**é—®é¢˜**: {result['question']}\n")
                report_lines.append(f"**åŒ…å«è™šæ„æ¦‚å¿µ**: {'æ˜¯' if result['contains_fictional_concept'] else 'å¦'}")
                
                if result["mentioned_fictional_terms"]:
                    report_lines.append(f"**æåˆ°çš„æœ¯è¯­**: {', '.join(result['mentioned_fictional_terms'])}")
                
                report_lines.append(f"**å›ç­”é•¿åº¦**: {result['response_length']} å­—ç¬¦")
                report_lines.append(f"**æ¨¡å‹å›ç­”**:\n```\n{result['response']}\n```\n")
                report_lines.append("---\n")
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = os.path.join(os.path.dirname(__file__), "experiment_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

def main():
    """ä¸»å‡½æ•°"""
    tester = FictionalConceptTester()
    
    # è¿è¡Œæµ‹è¯•
    results = tester.run_comprehensive_test()
    
    # åˆ†æç»“æœ
    tester.analyze_results(results)
    
    # ä¿å­˜ç»“æœ
    tester.save_results(results)
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    tester.generate_detailed_report(results)
    
    print("\nè™šæ„æ¦‚å¿µæµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main()